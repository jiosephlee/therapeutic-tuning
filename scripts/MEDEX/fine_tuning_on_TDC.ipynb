{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af217e9",
   "metadata": {},
   "source": [
    "# Fine-Tuning Prompt Ablations on Base Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "412fc656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.llm_configs' from '/home/josephL/fine-tuning-or-retrieval/scripts/MEDEX/../../utils/llm_configs.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add .. path \n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import utils.llm_training as llm_training\n",
    "import utils.llm_configs as llm_configs\n",
    "import wandb\n",
    "import logging\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from importlib import reload \n",
    "reload(llm_training)\n",
    "reload(llm_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d859d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_QUIET=false\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_QUIET=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f39076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiosephlee\u001b[0m (\u001b[33mupenn-ml\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/josephL/fine-tuning-or-retrieval/scripts/MEDEX/wandb/run-20250714_193455-zujzsciy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/upenn-ml/medex_fine_tuning/runs/zujzsciy' target=\"_blank\">AMES_fine_tuning/jiosephlee/therapeutic_fine_tuning_1M_v2</a></strong> to <a href='https://wandb.ai/upenn-ml/medex_fine_tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/upenn-ml/medex_fine_tuning' target=\"_blank\">https://wandb.ai/upenn-ml/medex_fine_tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/upenn-ml/medex_fine_tuning/runs/zujzsciy' target=\"_blank\">https://wandb.ai/upenn-ml/medex_fine_tuning/runs/zujzsciy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 19:34:56 - INFO - [__main__] - Training dataset example: {'text': 'SMILES: Nc1cccc([N+](=O)[O-])c1CO\\nQuestion: Is the drug represented by this SMILES string mutagenic?\\nAnswer: No, the drug is not mutagenic.', 'Y': 0}\n",
      "2025-07-14 19:34:56 - INFO - [__main__] - Validation dataset example: {'text': 'SMILES: O=[N+]([O-])c1ccc(-c2nc3n(c2[N+](=O)[O-])CCS3)cc1\\nQuestion: Is the drug represented by this SMILES string mutagenic?\\nAnswer:', 'Y': 1}\n",
      "2025-07-14 19:34:56 - INFO - [__main__] - Test dataset example: {'text': 'SMILES: CC(=O)Nc1ccc2c(=O)c(=O)c3cccc4ccc1c2c43\\nQuestion: Is the drug represented by this SMILES string mutagenic?\\nAnswer:', 'Y': 1}\n",
      "2025-07-14 19:34:56 - INFO - [__main__] - --- Model Configuration ---\n",
      "2025-07-14 19:34:56 - INFO - [__main__] - {\n",
      "  \"id\": \"jiosephlee/therapeutic_fine_tuning_1M_v2\",\n",
      "  \"torch_dtype\": \"auto\",\n",
      "  \"attn_implementation\": \"flash_attention_2\",\n",
      "  \"peft\": {\n",
      "    \"enabled\": false,\n",
      "    \"lora_r\": 16,\n",
      "    \"lora_alpha\": 32,\n",
      "    \"lora_dropout\": 0.05,\n",
      "    \"target_modules\": [\n",
      "      \"q_proj\",\n",
      "      \"k_proj\",\n",
      "      \"v_proj\",\n",
      "      \"o_proj\",\n",
      "      \"gate_proj\",\n",
      "      \"up_proj\",\n",
      "      \"down_proj\"\n",
      "    ],\n",
      "    \"add_eot_token\": false\n",
      "  },\n",
      "  \"quantization\": {\n",
      "    \"mode\": null\n",
      "  }\n",
      "}\n",
      "2025-07-14 19:34:56 - INFO - [__main__] - \n",
      "--- Loading Model for Training ---\n",
      "\n",
      "2025-07-14 19:34:56 - INFO - [__main__] - Loading model 'jiosephlee/therapeutic_fine_tuning_1M_v2' for training...\n",
      "2025-07-14 19:34:58 - INFO - [__main__] - Model and tokenizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Basic Configuration ---\n",
    "dataset =\"AMES\"\n",
    "metric=\"auroc\"\n",
    "model_name= \"jiosephlee/therapeutic_fine_tuning_1M_v2\"\n",
    "run_name = f\"{dataset}_fine_tuning/{model_name}\"\n",
    "# model_name=\"Qwen/Qwen2.5-0.5B\"\n",
    "_METHOD = 'text'\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - [%(name)s] - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"medex_fine_tuning\",\n",
    "    name=run_name,\n",
    "    tags=[\"Ablation\", \"AMES\"],\n",
    "    group=\"CPT prompt ablation\",\n",
    ")\n",
    "\n",
    "# --- Load Data and Preprocess---\n",
    "train_df = pd.read_csv(f'./../../data/TDC/{dataset}/train_df.csv')\n",
    "val_df = pd.read_csv(f'./../../data/TDC/{dataset}/val_df.csv')\n",
    "test_df = pd.read_csv(f'./../../data/TDC/{dataset}/test_df.csv')\n",
    "\n",
    "dataset =\"AMES\"\n",
    "\n",
    "def row_to_text( row, split='train', dataset='AMES_1'):\n",
    "    if dataset == 'AMES':\n",
    "        text = f\"SMILES: {row['Drug']}\\nQuestion: Is the drug represented by this SMILES string mutagenic?\\nAnswer:\"\n",
    "        if split == 'train':\n",
    "            text += f\"{' Yes, the drug is mutagenic.' if row['Y']==1 else ' No, the drug is not mutagenic.'}\"\n",
    "    if dataset == 'AMES_1':\n",
    "        text = f\"SMILES: {row['Drug']}\\nQuestion: Is the drug represented by this SMILES string mutagenic?\\nAnswer:\"\n",
    "        if split == 'train':\n",
    "            text += f\"{' Yes, the drug is mutagenic.' if row['Y']==1 else ' No, the drug is not mutagenic.'}\"\n",
    "    if dataset == 'AMES_2':\n",
    "        text = f\"SMILES: {row['Drug']}\\nQuestion: Is the drug represented by this SMILES string mutagenic?\\nAnswer:\"\n",
    "        if split == 'train':\n",
    "            text += f\"{' Yes.' if row['Y']==1 else ' No.'}\"\n",
    "    if dataset == 'AMES_3':\n",
    "        text = f\"Question: Is the drug represented by this SMILES string, {row['Drug']}, mutagenic?\\nAnswer:\"\n",
    "        if split == 'train':\n",
    "            text += f\"{' Yes, the drug is mutagenic.' if row['Y']==1 else ' No, the drug is not mutagenic.'}\"\n",
    "    elif dataset == 'Skin Reaction':\n",
    "        text = f\"Q: This is the SMILES string of the drug: {row['Drug']}. Can this drug cause skin reaction?\\nA: \"\n",
    "\n",
    "    return text\n",
    "\n",
    "def row_to_prompt( row, dataset='AMES'):\n",
    "    if dataset == 'AMES':\n",
    "        prompt = f\"SMILES: {row['Drug']}\\nQuestion: Is the drug represented by this SMILES string mutagenic?\\nAnswer:\"\n",
    "    elif dataset == 'Skin Reaction':\n",
    "        prompt = f\"Q: This is the SMILES string of the drug: {row['Drug']}. Can this drug cause skin reaction?\\nA: \"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def row_to_completion( row, dataset='AMES'):\n",
    "    if dataset == 'AMES':\n",
    "        completion = \" Yes, the drug is mutagenic.\"\n",
    "    elif dataset == 'Skin Reaction':\n",
    "        completion = f\"Question: This is the SMILES string of the drug: {row['Drug']}. Can this drug cause skin reaction?\\nA: \"\n",
    "    return completion\n",
    "\n",
    "def transform_df(train_df, val_df, test_df, dataset, method='text'):\n",
    "    if method == 'text': \n",
    "        train_df[\"text\"] = train_df.apply(row_to_text, axis=1, split = 'train', dataset = dataset)\n",
    "    elif method=='completion':\n",
    "        train_df[\"prompt\"] = train_df.apply(row_to_prompt, axis=1, dataset = dataset)\n",
    "        train_df[\"completion\"] = train_df.apply(row_to_completion, axis=1, dataset = dataset)\n",
    "    val_df[\"text\"] = val_df.apply(row_to_text, axis=1, split = 'val', dataset = dataset)\n",
    "    test_df[\"text\"] = test_df.apply(row_to_text, axis=1, split = 'test', dataset = dataset)\n",
    "\n",
    "transform_df(train_df, val_df, test_df, dataset, method=_METHOD)\n",
    "\n",
    "training_ds = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "training_ds = training_ds.select_columns(\n",
    "                    {\"text\", \"Y\", \"prompt\", \"completion\"}.intersection(training_ds.column_names)\n",
    "                )\n",
    "val_ds = Dataset.from_pandas(val_df, preserve_index=False)\n",
    "val_ds = val_ds.select_columns(\n",
    "                    {\"text\", \"Y\", \"prompt\", \"completion\"}.intersection(val_ds.column_names)\n",
    "                )\n",
    "test_ds = Dataset.from_pandas(test_df, preserve_index=False)\n",
    "test_ds = test_ds.select_columns(\n",
    "                    {\"text\", \"Y\", \"prompt\", \"completion\"}.intersection(test_ds.column_names)\n",
    "                )\n",
    "\n",
    "log.info(f\"Training dataset example: {training_ds[0]}\")\n",
    "log.info(f\"Validation dataset example: {val_ds[0]}\")\n",
    "log.info(f\"Test dataset example: {test_ds[0]}\")\n",
    "\n",
    "# --- Load Model ---\n",
    "model_config = llm_configs.ModelConfig(\n",
    "    id=model_name,\n",
    "    peft=llm_configs.PeftConfig(\n",
    "        enabled=False,\n",
    "        add_eot_token=False,  # No longer doing EOT token for LIMA\n",
    "    ),\n",
    "    quantization=llm_configs.QuantizationConfig(mode=None), # Use QLoRA\n",
    ")\n",
    "\n",
    "log.info(\"--- Model Configuration ---\")\n",
    "log.info(model_config.model_dump_json(indent=2))\n",
    "\n",
    "log.info(\"\\n--- Loading Model for Training ---\\n\")\n",
    "model, tokenizer = llm_training.load_model_for_training(model_config, log)\n",
    "\n",
    "lima_training_config = llm_configs.TrainingConfig(\n",
    "    run_name = run_name,\n",
    "    num_train_epochs = 10,\n",
    "    learning_rate  = 8e-5,\n",
    "    logging_strategy = \"steps\", \n",
    "    logging_steps = 1,\n",
    "    gradient_checkpointing=False,\n",
    "    context_length = 4096,\n",
    "    use_liger_kernel=True,\n",
    "    per_device_train_batch_size = 128,\n",
    "    gradient_accumulation_steps=1,\n",
    "    warmup_steps  = 0, # If 0, it does not override warmup ratio\n",
    "    warmup_ratio = 0.1, # Use our default warmup ratio instead\n",
    "    packing = False,\n",
    "    padding_free = True,\n",
    "    completion_only_loss=True,\n",
    "    sequential_sampling = False,\n",
    "    reverse_ffd_packing= False,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "lima_training_config.push_to_wandb(run)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3a2112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 19:35:10 - INFO - [__main__] - \n",
      "--- Starting AMES Fine-Tuning ---\n",
      "2025-07-14 19:35:10 - INFO - [__main__] - Starting SFT training run...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62d24ad8f8f4af691fba257cc5ab7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/5094 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994cbfdf94774e49afcdc427f410b475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/5094 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934448df1edb4e228a8d360366bcc127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/5094 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 19:35:11 - INFO - [liger_kernel.transformers.monkey_patch] - Applying Liger kernels to model instance with model type: qwen2 with kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied Liger kernels to Qwen2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 12:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.593200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.462200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.065200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.854400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.522900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.030800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.783100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.663100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.625500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.610100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.555700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.549900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.559100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.581800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.569500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.529600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.528500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.568100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.509100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.512700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.487400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.526200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.514700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.517800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.542900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.517000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.500100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.491100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.489700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.494700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.501300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.527000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.521400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.516000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.487900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.520600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.504300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.524800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.473900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.487200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.461400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.456000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.467100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.469300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.476900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.435700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.438400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.461500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.477400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.454600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.429900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.449100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.438000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.429700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.451200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.416000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.430900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.467500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.465800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.451800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.465800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.440400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.440300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.411400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.424300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.427900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.440400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.450700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.431200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.410400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.423100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.459200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.444300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.407700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.435300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.450900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.371100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.383400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.370800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.370700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.367500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.359400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.383400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.374100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.372200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.372900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.390300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.383900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.385500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.366500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.370100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.373900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.366100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.348300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.384600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.383100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.394400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.393500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.346500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.356000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.411500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.384300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.381000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.366300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.389800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.398100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.356500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.364800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.350100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.405200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.327700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.330300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.334400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.319800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.318300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.329400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.315100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.324600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.329100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.322300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.325400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.333400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.339900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.317000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.311800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.342800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.318500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.322100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.317700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.320300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.340400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.316400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.350200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.334200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.348300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.348500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.338700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.345800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.328600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.336800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.344800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.321200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.318500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.323800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.271100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.274500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.265600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.260500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.282300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.285600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.286300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.294000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.276100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.278200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.274600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.283700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.279100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.285100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.275900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.295300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.275600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.294900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.282200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.281700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.287400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.284500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.288300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.288100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.301800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.286600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.283100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.285200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.295500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.291900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.290700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.303100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.287100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.303700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.280700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.296300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.286600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.280800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>0.246400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>0.245500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.231900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.237400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.244600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.234500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.241100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>0.235100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>0.247900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.250500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>0.250200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>0.249200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>0.245000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>0.249800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>0.245400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>0.252500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>0.237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>0.248800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>0.254400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.245100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>0.242800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0.247900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>0.246900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.257700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.252900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>0.234700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>0.248200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.247700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>0.253100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.245800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>0.246900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>0.242600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>0.246800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.241900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>0.232500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.237400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.243000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>0.211200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.214400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>0.208100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>0.210100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>0.208700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.214600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>0.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.216800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>0.210900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.212100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>0.215800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>0.213200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>0.216500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>0.215900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.214200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.209800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>0.222300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>0.216600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>0.219800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.217200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>0.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>0.214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>0.215800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>0.223200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>0.215200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>0.215400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>0.216900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>0.221500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>0.223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.219300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>0.220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>0.218300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>0.211700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>0.220500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.218400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>0.218100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>0.221500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>0.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>0.211000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.210200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>0.198700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>0.197500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>0.196400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>0.193800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.195600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>0.190900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>0.194200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.194100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>0.193800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.191400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>0.195400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>0.200500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>0.192200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>0.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.197300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>0.192900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>0.194100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>0.191300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>0.194500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.189600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>0.193100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>0.193800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>0.193300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>0.192800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>0.195500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>0.189400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307</td>\n",
       "      <td>0.193900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>0.193800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>0.190600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.196100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>311</td>\n",
       "      <td>0.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>0.203600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313</td>\n",
       "      <td>0.201600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>0.203200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>0.193000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316</td>\n",
       "      <td>0.197200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>317</td>\n",
       "      <td>0.197600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>318</td>\n",
       "      <td>0.194300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>0.197800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.202500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>0.181300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322</td>\n",
       "      <td>0.182100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323</td>\n",
       "      <td>0.188700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>0.186600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326</td>\n",
       "      <td>0.183700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>0.181300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>0.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>0.187700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.184200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>0.181700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>0.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>0.182800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334</td>\n",
       "      <td>0.179800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>0.186400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>0.189200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337</td>\n",
       "      <td>0.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>338</td>\n",
       "      <td>0.183100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339</td>\n",
       "      <td>0.183300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.181900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341</td>\n",
       "      <td>0.184400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>0.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>343</td>\n",
       "      <td>0.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>0.191500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>0.181400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>0.187200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347</td>\n",
       "      <td>0.186400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>0.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>0.181200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.184200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>351</td>\n",
       "      <td>0.180300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.186500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353</td>\n",
       "      <td>0.183200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>354</td>\n",
       "      <td>0.189900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>0.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>0.187000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357</td>\n",
       "      <td>0.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358</td>\n",
       "      <td>0.186500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>0.186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361</td>\n",
       "      <td>0.183100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362</td>\n",
       "      <td>0.182400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>0.178300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>0.188900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>0.182900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>0.186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>367</td>\n",
       "      <td>0.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368</td>\n",
       "      <td>0.186100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369</td>\n",
       "      <td>0.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>371</td>\n",
       "      <td>0.179900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>0.182100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373</td>\n",
       "      <td>0.179900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>0.176600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.179200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376</td>\n",
       "      <td>0.180600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377</td>\n",
       "      <td>0.176400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>0.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379</td>\n",
       "      <td>0.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.184200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381</td>\n",
       "      <td>0.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>0.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>383</td>\n",
       "      <td>0.181800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.185800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>0.185100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386</td>\n",
       "      <td>0.185900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387</td>\n",
       "      <td>0.179900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388</td>\n",
       "      <td>0.180800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>389</td>\n",
       "      <td>0.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.180700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>391</td>\n",
       "      <td>0.185800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>0.186900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>0.179800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>0.178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>0.184100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>0.179800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>0.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>0.185800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>0.182600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.179700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 19:47:51 - INFO - [__main__] - SFT training complete.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▁▁▁▁▂▂▂▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/grad_norm</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▂▃▃▄▄▆▇████████▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/num_tokens</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>5538673706142720.0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>400</td></tr><tr><td>train/grad_norm</td><td>1.50781</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1797</td></tr><tr><td>train/num_tokens</td><td>2579260.0</td></tr><tr><td>train_loss</td><td>0.32779</td></tr><tr><td>train_runtime</td><td>760.5267</td></tr><tr><td>train_samples_per_second</td><td>66.98</td></tr><tr><td>train_steps_per_second</td><td>0.526</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AMES_fine_tuning/jiosephlee/therapeutic_fine_tuning_1M_v2</strong> at: <a href='https://wandb.ai/upenn-ml/medex_fine_tuning/runs/zujzsciy' target=\"_blank\">https://wandb.ai/upenn-ml/medex_fine_tuning/runs/zujzsciy</a><br> View project at: <a href='https://wandb.ai/upenn-ml/medex_fine_tuning' target=\"_blank\">https://wandb.ai/upenn-ml/medex_fine_tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250714_193455-zujzsciy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 19:47:52 - INFO - [__main__] - \n",
      "\n",
      "--- Fine-Tuning Complete ---\n",
      "\n",
      "\n",
      "2025-07-14 19:47:52 - INFO - [__main__] - Training arguments: SFTConfig(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "activation_offloading=False,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "assistant_only_loss=False,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "chat_template_path=None,\n",
      "completion_only_loss=True,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "dataset_kwargs=None,\n",
      "dataset_num_proc=None,\n",
      "dataset_text_field=text,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eos_token=<EOS_TOKEN>,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_packing=None,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.NO,\n",
      "eval_use_gather_object=False,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_revision=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=8e-05,\n",
      "length_column_name=length,\n",
      "liger_kernel_config=None,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=trainer_output/runs/Jul14_19-35-10_ShenLab,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.COSINE,\n",
      "max_grad_norm=1.0,\n",
      "max_length=4096,\n",
      "max_seq_length=None,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "model_init_kwargs=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=10,\n",
      "optim=OptimizerNames.PAGED_ADAMW_8BIT,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=trainer_output,\n",
      "overwrite_output_dir=False,\n",
      "packing=False,\n",
      "packing_strategy=ffd,\n",
      "pad_to_multiple_of=None,\n",
      "pad_token=<PAD_TOKEN>,\n",
      "padding_free=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=128,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=['wandb'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "reverse_ffd_packing=False,\n",
      "run_name=AMES_fine_tuning/jiosephlee/therapeutic_fine_tuning_1M_v2,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=SaveStrategy.NO,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=True,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.1,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.1,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log.info(f\"\\n--- Starting {dataset} Fine-Tuning ---\")\n",
    "trainer = llm_training.sft_train_on_dataset(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    log=log,\n",
    "    train_dataset=training_ds,\n",
    "    train_cfg=lima_training_config,\n",
    "    train=True,\n",
    "    use_liger_loss = True\n",
    ")\n",
    "\n",
    "log.info(\"\\n\\n--- Fine-Tuning Complete ---\\n\\n\")\n",
    "log.info(f\"Training arguments: {trainer.args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2128e0f",
   "metadata": {},
   "source": [
    "## Check if padding_free without packing is valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5251ac",
   "metadata": {},
   "source": [
    "I think when it was packed we had like wayyy fewer steps. like 20? when it was 10 epochs. Let's double check this. In a single batch, how many questions fit? when it's not packed it's simple. it's defined by the batch size. what about when it's packed?\n",
    "\n",
    "Are they the same shape? just longer? If so, why do we have attention masks in only one situations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee698ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  9501,  45978,     25,  ...,    292,     13, 151643]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'position_ids': tensor([[ 0,  1,  2,  ..., 50, 51, 52]], device='cuda:0'), 'labels': tensor([[  9501,  45978,     25,  ...,    292,     13, 151643]],\n",
      "       device='cuda:0')}\n",
      "128\n",
      "SMILES: C#C[C@]1(OC(C)=O)CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@@H]4[C@H]3CC[C@@]21C\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: Cc1ccc(C=O)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CCC(C)(C)C\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CCOC(=O)c1[nH]c2ccccc2c1/N=C/c1ccc(O)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: BrCc1ccccc1CBr\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CCC#N\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=[N+]([O-])c1ccc2c(c1)CCN2\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CCN(CC)S(=O)(=O)c1ccc(N)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CC1=Cc2nc3c(ccc4ccccc43)c(C)c2C(O)C1O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: OCc1cc2cccc3ccc4cc5ccccc5c1c4c32\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: NC(=O)N/N=C/C(=O)O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: N#Cc1cccc(/C=C/c2ccc(N)cc2)c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: C#CCO\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CCN(CC)CCNc1ccc2ncn3c4ccc(O)cc4c(=O)c1c23\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CN1CCN=C(c2ccccc2)c2cc(Cl)ccc21\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CCN=c1cc2oc3cc(NCC)c(C)cc3c(-c3ccccc3C(=O)OCC)c-2cc1C\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=C(O)c1ccc(N=Nc2ccc(O)c(C(=O)O)c2)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=C(NCO)NCO\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CC(C)c1ccccc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CC(C)=CCCC(C)CC=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: Oc1cc(Cl)c(Cl)c(Cl)c1Cl\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: c1cnc2c(c1)ccc1cc[nH]c12\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CCC(=O)NCc1ccccc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=C(O)c1cc(=O)c2c(OCC(O)COc3cccc4oc(C(=O)O)cc(=O)c34)cccc2o1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: Cc1cccc(C)c1[N+](=O)[O-]\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=C(CC(O)(CC(=O)OCCBr)C(=O)OCCBr)OCCBr\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: Nc1ccc(Cc2cc(O)c(N)c(Cl)c2)cc1Cl\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CCCCOC(=O)c1ccc(N)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=C1c2ccc(O)c(O)c2C(=O)c2c(O)ccc(O)c21\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CC(=O)Nc1ccc(OC(=O)c2ccccc2OC(C)=O)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CN(CCO)C(=O)Nc1ccc(Cl)c(Cl)c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=[N+]([O-])c1ccc2ccc3cccc4c3c2c1C1OC41\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: N#Cc1ccccc1[N+](=O)[O-]\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: C=C(C)C(=O)OCCCCCCCC(C)C\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=NN(CCCl)C(=O)NCCO\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: Cc1cc(N)ccc1NOS(=O)(=O)O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CCN(C#N)N=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: N#CCc1ccccc1[N+](=O)[O-]\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: Nc1cc(Cl)cc(Cl)c1O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CC(C)[N+](=O)[O-]\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CC(=O)Nc1cccc(N)c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CC(C)CN\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: Cn1c2ccccc2c2ccc([N+](=O)[O-])cc21\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: N=c1ccn2c(n1)O[C@@H]1[C@@H]2O[C@H](CO)[C@H]1O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: Clc1ccc(CC[C@H]2CO2)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: O=[N+]([O-])c1cc2c([nH]c3ccccc32)c([N+](=O)[O-])c1O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CC(=O)c1cccc([N+](=O)[O-])c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: N/C(=N\\OS(=O)(=O)O)c1ccccc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: [O-][n+]1cccc2c1C1OC1C=C2\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: Nc1ccc(N)c([N+](=O)[O-])c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: c1ccc2cc3c(ccc4ccccc43)cc2c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: O=C(O)CCCCCCCCCCCCCCCCCO\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CC(=O)Oc1ccc2c(c1)OC1(C)OOC21C\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: N#Cc1cc(I)c(O)c([N+](=O)[O-])c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CC(OP(=O)(OC(C)C(Br)CBr)OC(C)C(Br)CBr)C(Br)CBr\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CCC(C)c1ccccc1O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CCCCCCCCCCCCCCCC(=O)OCC(O)C1OC(O)=C(O)C1=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=C(O)CCCc1ccc(N(CCCl)CCCl)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CC(C)COS(C)(=O)=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CCCCOCCOCCO\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=[N+]([O-])CCO\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: Oc1cccc(O)c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CN1CCC(CN2c3ccccc3Sc3ccccc32)C1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CC=CCC=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: NNc1nc(-c2ccc(N)cc2)cs1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: O=[N+]([O-])c1ccc2ccc3cc4ccccc4c4ccc1c2c34\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CC(=O)/C(C)=N\\O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=[N+]([O-])c1cccc(CO)c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CC(=O)Nc1cccc2c1-c1ccccc1C2\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: NCCc1c[nH]c2ccccc12\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=[N+]([O-])c1cc2ccc3cc4ccccc4c4ccc(c1)c2c34\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: COS(C)(=O)=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CC(=O)c1ccc2[nH]c3c(C)cc([N+](=O)[O-])c(C)c3c2c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: Cc1cccc(-c2nc3ccccc3o2)c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CC(O)CN(C)N=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CCCCC(CC)COP(OCC(CC)CCCC)OCC(CC)CCCC\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: NC(CC(=O)O)C(=O)O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=[N+]([O-])c1ccc2c(c1)sc1ccccc12\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: O=C(O)c1cc([N+](=O)[O-])cc([N+](=O)[O-])c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CCOP(=S)(OCC)SCCl\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CC/C=C/C=C/C=C/C=C/C=C/C=C/OCC(O)CO\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: FC(F)(F)CCl\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CCOP(=O)(C#N)N(C)C\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: Cc1cc2c(c3ccc4ccccc4c13)CC(O)C2=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: O=C1CCCCCCCCCCCC(=O)OCCO1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: Cc1c2ccc3ccccc3c2cc2ccc(O)c(O)c12\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: Brc1ccc(Oc2cc(Br)c(Br)cc2Br)c(Br)c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=CN(O)c1ccc(Cl)c(Cl)c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=[N+]([O-])c1ccc2ccc3c4c(cc5ccc1c2c53)C=CCC4\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CC(C)(C)OOC(C)(C)C\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CC[C@@H](CO)[N+](=O)[O-]\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: NC(CCC(=O)O)C(=O)O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: c1ccc(OCC2CO2)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: NNc1ccc([N+](=O)[O-])cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: COc1cc([N+](=O)[O-])ccc1N\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: C=COCC(F)(F)F\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: Nc1ncnc2c1ncn2-c1ccc([N+](=O)[O-])cc1[N+](=O)[O-]\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CCC1=C(O)C(=O)c2c(O)c(O)c(O)c(O)c2C1=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CCCCCN1C2c3ccccc3-c3ccccc3C21\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: C(=N/N1Cc2[nH]c3ccccc3c2N=N1)\\c1ccc(Oc2ccccc2)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CC/C(=C(/CC)c1ccc(O)cc1)c1ccc(O)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CCCCC(CC)CO\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=C(CO)N(O)c1ccc(Cl)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=[N+]([O-])c1ccc(Oc2ccccc2)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: COc1cc2c(c3oc(=O)c4c(c13)C(O)CC4=O)C1C=COC1O2\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: ClCc1ccc2ccc3cccc4ccc1c2c34\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: Cc1ccc(C(=O)O)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: ClC1c2cccc3ccc4c5ccccc5cc1c4c23\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: O=C(O)[C@@H](O)[C@H](O)C(=O)O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: Cc1cn(C2CC(N=[N+]=[N-])C(CO)O2)c(=O)[nH]c1=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: Clc1ccccc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CC/C=C/C=C/C=C/C=C/OCC(O)CO\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CC(=O)Nc1ccc(OCC(O)CNC(C)C)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=NN1CCS[C@@H]1[C@H](O)[C@H](O)[C@H](O)[C@H](O)CO\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CC(N)C(O)c1ccccc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CCCC(=O)Nc1ccc(OC[C@H](O)CNC(C)C)c(C(C)=O)c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CCO[P@](=O)(Oc1ccc([N+](=O)[O-])cc1)c1ccccc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: c1cc(OC[C@H]2CO2)cc(OC[C@H]2CO2)c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CC(=O)Oc1ccccc1C(=O)Oc1ccccc1C(=O)O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: Cc1cccc2ccc3cc4ccccc4cc3c12\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CC(O)COCC(C)O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: O=CCCCC=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CC1=CC(=O)c2[nH]c(C)c3c4ccccc4nc-3c2C1=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: O=[N+]([O-])c1ccc2ccc3cccc4c3c2c1[C@@H]1O[C@H]41\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>SMILES: CCC(=O)Nc1ccc(Cl)c(Cl)c1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: CN(C)c1ccc(C(=C2C=CC(=[N+](C)C)C=C2)c2ccc(N(C)C)cc2)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: [O-][n+]1cc2cccnc2cn1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>SMILES: c1ccc2c(c1)-c1ccc3ccccc3c1C1NC21\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "lima_training_config = llm_configs.TrainingConfig(\n",
    "    run_name = f\"{dataset} fine-tuning with {model_name}\",\n",
    "    num_train_epochs = 10,\n",
    "    learning_rate  = 8e-5,\n",
    "    logging_strategy = \"steps\", \n",
    "    logging_steps = 1,\n",
    "    gradient_checkpointing=False,\n",
    "    context_length = 4096,\n",
    "    use_liger_kernel=True,\n",
    "    per_device_train_batch_size = 128,\n",
    "    gradient_accumulation_steps=1,\n",
    "    warmup_steps  = 0, # If 0, it does not override warmup ratio\n",
    "    warmup_ratio = 0.1, # Use our default warmup ratio instead\n",
    "    packing = False,\n",
    "    padding_free = True,\n",
    "    sequential_sampling = False,\n",
    "    reverse_ffd_packing= False,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = llm_training.sft_train_on_dataset(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    log=log,\n",
    "    train_dataset=training_ds,\n",
    "    train_cfg=lima_training_config,\n",
    "    train=False,\n",
    "    use_liger_loss = True\n",
    ")\n",
    "\n",
    "for i, batch in enumerate(trainer.get_train_dataloader()):\n",
    "    count = 0\n",
    "    if i == 0:\n",
    "        print(batch)\n",
    "        for j in batch['position_ids'][0]:\n",
    "            if j == 0:\n",
    "                count+=1\n",
    "        print(count)\n",
    "        print(tokenizer.decode(batch['input_ids'][0].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f46b43",
   "metadata": {},
   "source": [
    "## Eval on Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115fea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset='AMES_2'\n",
    "# def row_to_text( row, split='train', dataset='AMES_1'):\n",
    "#     if dataset == 'AMES_1':\n",
    "#         text = f\"SMILES: {row['Drug']}\\nQuestion: Is the drug represented by this SMILES string mutagenic?\\nAnswer:\"\n",
    "#         if split == 'train':\n",
    "#             text += f\"{' Yes, the drug is mutagenic.' if row['Y']==1 else ' No, the drug is not mutagenic.'}\"\n",
    "#     if dataset == 'AMES_2':\n",
    "#         text = f\"SMILES: {row['Drug']}\\nQuestion: Is the drug represented by this SMILES string mutagenic?\\nAnswer:\"\n",
    "#         if split == 'train':\n",
    "#             text += f\"{' Yes.' if row['Y']==1 else ' No.'}\"\n",
    "#     if dataset == 'AMES_3':\n",
    "#         text = f\"Question: Is the drug represented by this SMILES string, {row['Drug']}, mutagenic?\\nAnswer:\"\n",
    "#         if split == 'train':\n",
    "#             text += f\"{' Yes.' if row['Y']==1 else ' No.'}\"\n",
    "#     elif dataset == 'Skin Reaction':\n",
    "#         text = f\"Q: This is the SMILES string of the drug: {row['Drug']}. Can this drug cause skin reaction?\\nA: \"\n",
    "\n",
    "#     return text\n",
    "\n",
    "train_df[\"text\"] = train_df.apply(row_to_text, axis=1, split = 'test', dataset = dataset)\n",
    "training_ds = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "training_ds = training_ds.select_columns(\n",
    "                    {\"text\", \"Y\", \"prompt\", \"completion\"}.intersection(training_ds.column_names)\n",
    "                )\n",
    "\n",
    "# val_df[\"text\"] = val_df.apply(row_to_text, axis=1, split = 'val', dataset = dataset)\n",
    "# val_ds = Dataset.from_pandas(val_df, preserve_index=False)\n",
    "# val_ds = val_ds.select_columns(\n",
    "#                     {\"text\", \"Y\", \"prompt\", \"completion\"}.intersection(val_ds.column_names)\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9734e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on test set:   0%|          | 1/5094 [00:00<25:00,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: SMILES: Nc1cccc([N+](=O)[O-])c1CO\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer:\n",
      "\n",
      "Generated response: SMILES: Nc1cccc([N+](=O)[O-])c1CO\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>\n",
      "GT answer: no\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on test set:   0%|          | 2/5094 [00:00<22:51,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: SMILES: O=[N+]([O-])c1cccc(O)c1[N+](=O)[O-]\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer:\n",
      "\n",
      "Generated response: SMILES: O=[N+]([O-])c1cccc(O)c1[N+](=O)[O-]\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on test set:   0%|          | 3/5094 [00:00<20:55,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: SMILES: Cc1cc(Cl)ccc1O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer:\n",
      "\n",
      "Generated response: SMILES: Cc1cc(Cl)ccc1O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>\n",
      "GT answer: no\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on test set:   0%|          | 4/5094 [00:01<21:05,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: SMILES: CNC(=O)Oc1ccccc1OC(C)C\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer:\n",
      "\n",
      "Generated response: SMILES: CNC(=O)Oc1ccccc1OC(C)C\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on test set:   0%|          | 5/5094 [00:01<20:19,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: SMILES: Cc1cc([N+](=O)[O-])cc([N+](=O)[O-])c1C\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer:\n",
      "\n",
      "Generated response: SMILES: Cc1cc([N+](=O)[O-])cc([N+](=O)[O-])c1C\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>\n",
      "GT answer: no\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on test set:   0%|          | 6/5094 [00:01<20:44,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: SMILES: Nc1ccc(Cl)cc1Cl\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer:\n",
      "\n",
      "Generated response: SMILES: Nc1ccc(Cl)cc1Cl\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on test set:   0%|          | 7/5094 [00:01<20:09,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: SMILES: Cc1cccc([N+](=O)[O-])c1C\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer:\n",
      "\n",
      "Generated response: SMILES: Cc1cccc([N+](=O)[O-])c1C\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on test set:   0%|          | 8/5094 [00:01<20:29,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: SMILES: O=[N+]([O-])c1ccccc1SSC(F)=C(Cl)Cl\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer:\n",
      "\n",
      "Generated response: SMILES: O=[N+]([O-])c1ccccc1SSC(F)=C(Cl)Cl\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on test set:   0%|          | 9/5094 [00:02<19:25,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: SMILES: CN(Cc1ccc(F)cc1)N=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer:\n",
      "\n",
      "Generated response: SMILES: CN(Cc1ccc(F)cc1)N=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on test set:   0%|          | 10/5094 [00:02<20:31,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: SMILES: Clc1cccc(Cl)c1Cl\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer:\n",
      "\n",
      "Generated response: SMILES: Clc1cccc(Cl)c1Cl\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>\n",
      "GT answer: no\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on test set:  35%|███▍      | 1772/5094 [06:56<13:21,  4.14it/s]"
     ]
    }
   ],
   "source": [
    "# --- Evaluate ---\n",
    "inference_cfg = llm_configs.InferenceConfig(\n",
    "    temperature=0,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.0,\n",
    "    max_new_tokens=64,\n",
    ")\n",
    "\n",
    "targets, preds = [], []\n",
    "\n",
    "for i in tqdm(range(len(training_ds)), desc=\"Inference on test set\"):\n",
    "    row = training_ds[i]\n",
    "    prompt = row[\"text\"]\n",
    "    gt_answer = \"yes\" if row[\"Y\"] == 1 else \"no\"\n",
    "    \n",
    "    gen_text = llm_training.generate_text(model, tokenizer, prompt, inference_cfg)\n",
    "    \n",
    "    # Extract generated text (remove the prompt part)\n",
    "    generated_response = gen_text[len(prompt):].strip().lower()\n",
    "\n",
    "    if i < 10:\n",
    "        print(f\"Prompt: {prompt}\\n\")\n",
    "        print(f\"Generated response: {gen_text}\")\n",
    "        print(f\"GT answer: {gt_answer}\")\n",
    "        print(\"-\"*100)\n",
    "        # print(llm_training.analyze_text_generation(model, tokenizer, prompt, 'cuda', 4))\n",
    "    # Simple matching - check if \"yes\" or \"no\" appears in the response\n",
    "    if \"yes\" in generated_response:\n",
    "        pred_answer = 1\n",
    "    elif \"no\" in generated_response:\n",
    "        pred_answer = 0\n",
    "    else:\n",
    "        probs = llm_training.extract_logits_first_step(model, tokenizer, prompt, [\"Yes\",\"No\"])\n",
    "        pred_answer = int(probs[\"Yes\"] > probs[\"No\"]) \n",
    "        # If neither yes nor no is found, skip this example\n",
    "        # continue\n",
    "\n",
    "    \n",
    "    targets.append(gt_answer)\n",
    "    preds.append(pred_answer)\n",
    "\n",
    "# ------------------\n",
    "# Compute Accuracy\n",
    "# ------------------\n",
    "targets = np.array(targets)\n",
    "preds = np.array(preds)\n",
    "\n",
    "if metric == \"accuracy\":\n",
    "    accuracy = np.mean(targets == preds)\n",
    "    print(f\"\\nAccuracy on {len(targets)} examples: {accuracy:.4f}\")\n",
    "elif metric == \"auroc\":\n",
    "    auroc = roc_auc_score(targets, preds)\n",
    "    print(f\"\\nAUROC on {len(targets)} examples: {auroc:.4f}\")\n",
    "\n",
    "# Save model before we LIMA tune\n",
    "#model.push_to_hub('jiosephlee/therapeutic_fine_tuning_36M')\n",
    "#tokenizer.push_to_hub('jiosephlee/therapeutic_fine_tuning_36M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d828f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on validation set:   0%|          | 0/727 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated response: SMILES: O=[N+]([O-])c1ccc(-c2nc3n(c2[N+](=O)[O-])CCS3)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on validation set:   0%|          | 1/727 [00:00<06:36,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: SMILES: O=[N+]([O-])c1ccc(-c2nc3n(c2[N+](=O)[O-])CCS3)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug\n",
      "\n",
      "➡️ Generated Token #1: \"Yes\" (Probability: 90.37%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"Yes\" (90.37%)\n",
      "      2. \"No\" (9.53%)\n",
      "      3. \"[\" (0.06%)\n",
      "      4. \"Yes\" (0.01%)\n",
      "      5. \"S\" (0.01%)\n",
      "\n",
      "➡️ Generated Token #2: \",\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \",\" (100.00%)\n",
      "      2. \"<|endoftext|>\" (0.00%)\n",
      "      3. \".\" (0.00%)\n",
      "      4. \".,\" (0.00%)\n",
      "      5. \"ess\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #3: \"the\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"the\" (100.00%)\n",
      "      2. \"the\" (0.00%)\n",
      "      3. \"The\" (0.00%)\n",
      "      4. \"is\" (0.00%)\n",
      "      5. \"a\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #4: \"drug\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"drug\" (100.00%)\n",
      "      2. \"Drug\" (0.00%)\n",
      "      3. \"Drug\" (0.00%)\n",
      "      4. \"medication\" (0.00%)\n",
      "      5. \"drug\" (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on validation set:   0%|          | 2/727 [00:00<05:43,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated response: SMILES: O=[N+]([O-])c1c(-c2ccc(Cl)cc2)nc2n1CCS2\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Output: SMILES: O=[N+]([O-])c1c(-c2ccc(Cl)cc2)nc2n1CCS2\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug\n",
      "\n",
      "➡️ Generated Token #1: \"Yes\" (Probability: 65.11%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"Yes\" (65.11%)\n",
      "      2. \"No\" (34.85%)\n",
      "      3. \"Cl\" (0.02%)\n",
      "      4. \"[\" (0.00%)\n",
      "      5. \"no\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #2: \",\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \",\" (100.00%)\n",
      "      2. \"<|endoftext|>\" (0.00%)\n",
      "      3. \".\" (0.00%)\n",
      "      4. \".,\" (0.00%)\n",
      "      5. \"ude\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #3: \"the\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"the\" (100.00%)\n",
      "      2. \"the\" (0.00%)\n",
      "      3. \"Cl\" (0.00%)\n",
      "      4. \"The\" (0.00%)\n",
      "      5. \"is\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #4: \"drug\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"drug\" (100.00%)\n",
      "      2. \"medication\" (0.00%)\n",
      "      3. \"Drug\" (0.00%)\n",
      "      4. \"drug\" (0.00%)\n",
      "      5. \"Drug\" (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on validation set:   0%|          | 3/727 [00:01<04:42,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated response: SMILES: Cc1ccc(-c2nc3n(c2[N+](=O)[O-])CCS3)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Output: SMILES: Cc1ccc(-c2nc3n(c2[N+](=O)[O-])CCS3)cc1\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug\n",
      "\n",
      "➡️ Generated Token #1: \"Yes\" (Probability: 95.75%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"Yes\" (95.75%)\n",
      "      2. \"No\" (4.21%)\n",
      "      3. \"Yes\" (0.02%)\n",
      "      4. \"[\" (0.00%)\n",
      "      5. \"S\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #2: \",\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \",\" (100.00%)\n",
      "      2. \"<|endoftext|>\" (0.00%)\n",
      "      3. \".\" (0.00%)\n",
      "      4. \",'\" (0.00%)\n",
      "      5. \",\"\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #3: \"the\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"the\" (100.00%)\n",
      "      2. \"the\" (0.00%)\n",
      "      3. \"The\" (0.00%)\n",
      "      4. \"there\" (0.00%)\n",
      "      5. \"thed\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #4: \"drug\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"drug\" (100.00%)\n",
      "      2. \"medication\" (0.00%)\n",
      "      3. \"Drug\" (0.00%)\n",
      "      4. \"drugs\" (0.00%)\n",
      "      5. \"Drug\" (0.00%)\n",
      "Generated response: SMILES: COC(=O)[C@]12O[C@@]1(C)[C@@](C)(O)NC2=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on validation set:   1%|          | 4/727 [00:01<05:14,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: SMILES: COC(=O)[C@]12O[C@@]1(C)[C@@](C)(O)NC2=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug\n",
      "\n",
      "➡️ Generated Token #1: \"Yes\" (Probability: 98.19%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"Yes\" (98.19%)\n",
      "      2. \"No\" (1.80%)\n",
      "      3. \"Yes\" (0.01%)\n",
      "      4. \"NC\" (0.00%)\n",
      "      5. \"The\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #2: \",\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \",\" (100.00%)\n",
      "      2. \"<|endoftext|>\" (0.00%)\n",
      "      3. \".\" (0.00%)\n",
      "      4. \",\"\" (0.00%)\n",
      "      5. \",N\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #3: \"the\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"the\" (100.00%)\n",
      "      2. \"the\" (0.00%)\n",
      "      3. \"The\" (0.00%)\n",
      "      4. \"is\" (0.00%)\n",
      "      5. \"_the\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #4: \"drug\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"drug\" (100.00%)\n",
      "      2. \"Drug\" (0.00%)\n",
      "      3. \"Drug\" (0.00%)\n",
      "      4. \"drug\" (0.00%)\n",
      "      5. \"medication\" (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on validation set:   1%|          | 5/727 [00:02<05:20,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated response: SMILES: CC[C@@]12O[C@]1(C(=O)OC)C(=O)N[C@]2(C)O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Output: SMILES: CC[C@@]12O[C@]1(C(=O)OC)C(=O)N[C@]2(C)O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug\n",
      "\n",
      "➡️ Generated Token #1: \"No\" (Probability: 77.47%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"No\" (77.47%)\n",
      "      2. \"Yes\" (22.20%)\n",
      "      3. \"N\" (0.28%)\n",
      "      4. \"The\" (0.02%)\n",
      "      5. \"In\" (0.01%)\n",
      "\n",
      "➡️ Generated Token #2: \",\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \",\" (100.00%)\n",
      "      2. \"<|endoftext|>\" (0.00%)\n",
      "      3. \".\" (0.00%)\n",
      "      4. \",M\" (0.00%)\n",
      "      5. \",\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #3: \"the\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"the\" (100.00%)\n",
      "      2. \"the\" (0.00%)\n",
      "      3. \"The\" (0.00%)\n",
      "      4. \"_the\" (0.00%)\n",
      "      5. \"this\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #4: \"drug\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"drug\" (100.00%)\n",
      "      2. \"Drug\" (0.00%)\n",
      "      3. \"Drug\" (0.00%)\n",
      "      4. \"drug\" (0.00%)\n",
      "      5. \"drugs\" (0.00%)\n",
      "Generated response: SMILES: COC(=O)C12OC1(C)C(O)(C(C)C)NC2=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on validation set:   1%|          | 6/727 [00:02<05:47,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: SMILES: COC(=O)C12OC1(C)C(O)(C(C)C)NC2=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug\n",
      "\n",
      "➡️ Generated Token #1: \"Yes\" (Probability: 97.70%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"Yes\" (97.70%)\n",
      "      2. \"No\" (2.30%)\n",
      "      3. \"Yes\" (0.00%)\n",
      "      4. \"OC\" (0.00%)\n",
      "      5. \"N\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #2: \",\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \",\" (100.00%)\n",
      "      2. \"<|endoftext|>\" (0.00%)\n",
      "      3. \".\" (0.00%)\n",
      "      4. \",'\" (0.00%)\n",
      "      5. \",\"\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #3: \"the\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"the\" (100.00%)\n",
      "      2. \"the\" (0.00%)\n",
      "      3. \"The\" (0.00%)\n",
      "      4. \"_the\" (0.00%)\n",
      "      5. \"there\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #4: \"drug\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"drug\" (100.00%)\n",
      "      2. \"Drug\" (0.00%)\n",
      "      3. \"Drug\" (0.00%)\n",
      "      4. \"drug\" (0.00%)\n",
      "      5. \"medication\" (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on validation set:   1%|          | 7/727 [00:03<05:37,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated response: SMILES: CCC12OC1(C(=O)OC)C(=O)NC2(C)O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Output: SMILES: CCC12OC1(C(=O)OC)C(=O)NC2(C)O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug\n",
      "\n",
      "➡️ Generated Token #1: \"Yes\" (Probability: 75.49%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"Yes\" (75.49%)\n",
      "      2. \"No\" (24.51%)\n",
      "      3. \"Yes\" (0.00%)\n",
      "      4. \"YES\" (0.00%)\n",
      "      5. \"NO\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #2: \",\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \",\" (100.00%)\n",
      "      2. \".\" (0.00%)\n",
      "      3. \"<|endoftext|>\" (0.00%)\n",
      "      4. \",\"\" (0.00%)\n",
      "      5. \",'\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #3: \"the\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"the\" (100.00%)\n",
      "      2. \"the\" (0.00%)\n",
      "      3. \"The\" (0.00%)\n",
      "      4. \"the\" (0.00%)\n",
      "      5. \"_the\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #4: \"drug\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"drug\" (100.00%)\n",
      "      2. \"Drug\" (0.00%)\n",
      "      3. \"medication\" (0.00%)\n",
      "      4. \"drug\" (0.00%)\n",
      "      5. \"药物\" (0.00%)\n",
      "Generated response: SMILES: C/C=C(\\C=C(C)\\C=C(C)\\C=C\\C=C(/C)C(=O)[C@@]12O[C@@H]1[C@](O)(CCO)NC2=O)C(=O)OC\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug is not mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Output: SMILES: C/C=C(\\C=C(C)\\C=C(C)\\C=C\\C=C(/C)C(=O)[C@@]12O[C@@H]1[C@](O)(CCO)NC2=O)C(=O)OC\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: No, the drug\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on validation set:   1%|          | 8/727 [00:03<06:07,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️ Generated Token #1: \"No\" (Probability: 59.25%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"No\" (59.25%)\n",
      "      2. \"Yes\" (40.72%)\n",
      "      3. \"C\" (0.01%)\n",
      "      4. \"Based\" (0.01%)\n",
      "      5. \"no\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #2: \",\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \",\" (100.00%)\n",
      "      2. \"<|endoftext|>\" (0.00%)\n",
      "      3. \".\" (0.00%)\n",
      "      4. \",O\" (0.00%)\n",
      "      5. \"ude\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #3: \"the\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"the\" (100.00%)\n",
      "      2. \"The\" (0.00%)\n",
      "      3. \"the\" (0.00%)\n",
      "      4. \"_the\" (0.00%)\n",
      "      5. \"-the\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #4: \"drug\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"drug\" (100.00%)\n",
      "      2. \"Drug\" (0.00%)\n",
      "      3. \"Drug\" (0.00%)\n",
      "      4. \"medication\" (0.00%)\n",
      "      5. \"drugs\" (0.00%)\n",
      "Generated response: SMILES: COC(=O)C12OC1(C)C(C)(O)NC2=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on validation set:   1%|          | 9/727 [00:04<05:58,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: SMILES: COC(=O)C12OC1(C)C(C)(O)NC2=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug\n",
      "\n",
      "➡️ Generated Token #1: \"Yes\" (Probability: 96.69%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"Yes\" (96.69%)\n",
      "      2. \"No\" (3.31%)\n",
      "      3. \"Yes\" (0.00%)\n",
      "      4. \"OC\" (0.00%)\n",
      "      5. \"NO\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #2: \",\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \",\" (100.00%)\n",
      "      2. \"<|endoftext|>\" (0.00%)\n",
      "      3. \".\" (0.00%)\n",
      "      4. \",N\" (0.00%)\n",
      "      5. \",\"\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #3: \"the\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"the\" (100.00%)\n",
      "      2. \"the\" (0.00%)\n",
      "      3. \"The\" (0.00%)\n",
      "      4. \"_the\" (0.00%)\n",
      "      5. \"the\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #4: \"drug\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"drug\" (100.00%)\n",
      "      2. \"Drug\" (0.00%)\n",
      "      3. \"drug\" (0.00%)\n",
      "      4. \"Drug\" (0.00%)\n",
      "      5. \"medication\" (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on validation set:   1%|▏         | 10/727 [00:04<06:03,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated response: SMILES: COC(=O)[C@]12O[C@@]1(C)[C@](O)(C(C)C)NC2=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug is mutagenic.<|endoftext|>\n",
      "GT answer: yes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Output: SMILES: COC(=O)[C@]12O[C@@]1(C)[C@](O)(C(C)C)NC2=O\n",
      "Question: Is the drug represented by this SMILES string mutagenic?\n",
      "Answer: Yes, the drug\n",
      "\n",
      "➡️ Generated Token #1: \"Yes\" (Probability: 96.22%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"Yes\" (96.22%)\n",
      "      2. \"No\" (3.73%)\n",
      "      3. \"C\" (0.02%)\n",
      "      4. \"The\" (0.01%)\n",
      "      5. \"N\" (0.01%)\n",
      "\n",
      "➡️ Generated Token #2: \",\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \",\" (100.00%)\n",
      "      2. \"<|endoftext|>\" (0.00%)\n",
      "      3. \".\" (0.00%)\n",
      "      4. \",\"\" (0.00%)\n",
      "      5. \",'\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #3: \"the\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"the\" (100.00%)\n",
      "      2. \"the\" (0.00%)\n",
      "      3. \"The\" (0.00%)\n",
      "      4. \"is\" (0.00%)\n",
      "      5. \"_the\" (0.00%)\n",
      "\n",
      "➡️ Generated Token #4: \"drug\" (Probability: 100.00%)\n",
      "   Top 5 candidates for this position:\n",
      "      1. \"drug\" (100.00%)\n",
      "      2. \"Drug\" (0.00%)\n",
      "      3. \"Drug\" (0.00%)\n",
      "      4. \"drug\" (0.00%)\n",
      "      5. \"medication\" (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference on validation set: 100%|██████████| 727/727 [03:52<00:00,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUROC on 727 examples: 0.7757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate ---\n",
    "inference_cfg = llm_configs.InferenceConfig(\n",
    "    temperature=0,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.0,\n",
    "    max_new_tokens=64,\n",
    ")\n",
    "\n",
    "targets, preds = [], []\n",
    "\n",
    "for i in tqdm(range(len(val_ds)), desc=\"Inference on validation set\"):\n",
    "    row = val_ds[i]\n",
    "    prompt = row[\"text\"]\n",
    "    gt_answer = \"yes\" if row[\"Y\"] == 1 else \"no\"\n",
    "    \n",
    "    gen_text = llm_training.generate_text(model, tokenizer, prompt, inference_cfg)\n",
    "    \n",
    "    # Extract generated text (remove the prompt part)\n",
    "    generated_response = gen_text[len(prompt):].strip().lower()\n",
    "\n",
    "    if i < 10:\n",
    "        # print(f\"Prompt: {prompt}\")\n",
    "        print(f\"Generated response: {gen_text}\")\n",
    "        print(f\"GT answer: {gt_answer}\")\n",
    "        print(\"-\"*100)\n",
    "    if i == 10:\n",
    "        print(llm_training.analyze_text_generation(model, tokenizer, prompt, 'cuda', 4))\n",
    "    # Simple matching - check if \"yes\" or \"no\" appears in the response\n",
    "    if \"yes\" in generated_response:\n",
    "        pred_answer = 1\n",
    "    elif \"no\" in generated_response:\n",
    "        pred_answer = 0\n",
    "    else:\n",
    "        probs = llm_training.extract_logits_first_step(model, tokenizer, prompt, [\"Yes\",\"No\"])\n",
    "        pred_answer = int(probs[\"Yes\"] > probs[\"No\"]) \n",
    "        # If neither yes nor no is found, skip this example\n",
    "        # continue\n",
    "\n",
    "    \n",
    "    targets.append(gt_answer)\n",
    "    preds.append(pred_answer)\n",
    "\n",
    "# ------------------\n",
    "# Compute Accuracy\n",
    "# ------------------\n",
    "targets = np.array(targets)\n",
    "preds = np.array(preds)\n",
    "\n",
    "if metric == \"accuracy\":\n",
    "    accuracy = np.mean(targets == preds)\n",
    "    print(f\"\\nAccuracy on {len(targets)} examples: {accuracy:.4f}\")\n",
    "elif metric == \"auroc\":\n",
    "    auroc = roc_auc_score(targets, preds)\n",
    "    print(f\"\\nAUROC on {len(targets)} examples: {auroc:.4f}\")\n",
    "\n",
    "# Save model before we LIMA tune\n",
    "#model.push_to_hub('jiosephlee/therapeutic_fine_tuning_36M')\n",
    "#tokenizer.push_to_hub('jiosephlee/therapeutic_fine_tuning_36M')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
